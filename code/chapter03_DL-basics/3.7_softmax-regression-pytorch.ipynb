{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 softmax回归的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:27.276397Z",
     "start_time": "2024-01-14T11:32:27.034384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torchvision\n",
    "# import d2lzh_pytorch as d2l\n",
    "# from d2l import torch as d2l\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def show_singe_image(image, label):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image.view((28, 28)).numpy())  # 假设输入的图像是单通道的灰度图像\n",
    "    ax.set_title(text_labels[label])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:27.279841Z",
     "start_time": "2024-01-14T11:32:27.277950Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.1 获取和读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
    "    else:\n",
    "        num_workers = 4\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_iter, test_iter\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:27.283390Z",
     "start_time": "2024-01-14T11:32:27.281969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.140172Z",
     "start_time": "2024-01-14T11:32:27.284051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/rainbow/Datasets/FashionMNIST/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.2 定义和初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.140454Z",
     "start_time": "2024-01-14T11:32:55.131455Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "# class LinearNet(nn.Module):\n",
    "#     def __init__(self, num_inputs, num_outputs):\n",
    "#         super(LinearNet, self).__init__()\n",
    "#         self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "#     def forward(self, x): # x shape: (batch, 1, 28, 28)\n",
    "#         y = self.linear(x.view(x.shape[0], -1))\n",
    "#         return y\n",
    "    \n",
    "# net = LinearNet(num_inputs, num_outputs)\n",
    "\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(\n",
    "    # FlattenLayer(),\n",
    "    # nn.Linear(num_inputs, num_outputs)\n",
    "    OrderedDict([\n",
    "        # ('flatten', FlattenLayer()),\n",
    "        ('flatten', nn.Flatten()),\n",
    "        ('linear1', nn.Linear(num_inputs, 1000)),\n",
    "        ('sigmoid', nn.Sigmoid()),\n",
    "        ('linear', nn.Linear(1000, num_outputs))\n",
    "        # ('softmax', nn.Softmax(dim=1))\n",
    "    ])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear1): Linear(in_features=784, out_features=1000, bias=True)\n  (sigmoid): Sigmoid()\n  (linear): Linear(in_features=1000, out_features=10, bias=True)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.147426Z",
     "start_time": "2024-01-14T11:32:55.137622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.147664Z",
     "start_time": "2024-01-14T11:32:55.141394Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.175253Z",
     "start_time": "2024-01-14T11:32:55.145094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([10, 1000]), torch.Size([10]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.normal_(net.linear.weight, mean=0, std=0.01)\n",
    "init.normal_(net.linear1.weight, mean=0, std=0.01)\n",
    "init.constant_(net.linear.bias, val=0)\n",
    "init.constant_(net.linear1.bias, val=0)\n",
    "net.linear.weight.size(), net.linear.bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# net.linear2.weight.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.175421Z",
     "start_time": "2024-01-14T11:32:55.160287Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.3 softmax和交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.175538Z",
     "start_time": "2024-01-14T11:32:55.163448Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.4 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:55.175603Z",
     "start_time": "2024-01-14T11:32:55.166260Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.5 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    show_singe_image(X[0], y[0])\n",
    "    # print(X[0].size())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:57.204524Z",
     "start_time": "2024-01-14T11:32:55.168591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "\n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "\n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\n",
    "\n",
    "\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:33:42.251639Z",
     "start_time": "2024-01-14T11:33:42.243521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T11:32:57.410702Z",
     "start_time": "2024-01-14T11:32:57.207758Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m net \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# optimizer = optimizer.to(device='cuda')\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m net\u001B[38;5;241m.\u001B[39mnamed_parameters():\n",
      "File \u001B[0;32m~/miniconda3/envs/pt2/lib/python3.9/site-packages/torch/nn/modules/module.py:1160\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1156\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m-> 1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pt2/lib/python3.9/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/pt2/lib/python3.9/site-packages/torch/nn/modules/module.py:833\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    829\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 833\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/miniconda3/envs/pt2/lib/python3.9/site-packages/torch/nn/modules/module.py:1158\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m-> 1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pt2/lib/python3.9/site-packages/torch/cuda/__init__.py:289\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    285\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    286\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    287\u001B[0m     )\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    292\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    293\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "# d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n",
    "\n",
    "net = net.to(device='cuda')\n",
    "# optimizer = optimizer.to(device='cuda')\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Parameter {name} is on device {param.device}\")\n",
    "\n",
    "for X, y in train_iter:\n",
    "    X = X.to(device='cuda')\n",
    "    y = y.to(device='cuda')\n",
    "for X, y in test_iter:\n",
    "    X = X.to(device='cuda')\n",
    "    y = y.to(device='cuda')\n",
    "print(\"now training\")\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "def make_ten_prediction(data_iter):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "    images, labels = [], []\n",
    "    num_rows, num_cols, num_images = 2, 5, 10\n",
    "    y_hat = []\n",
    "    for X, y in data_iter:\n",
    "        global net\n",
    "        net = net.to(device='cpu')\n",
    "        batch_out = net(X)\n",
    "        for i in range(10):\n",
    "            r = random.randint(0, 255)\n",
    "            images.append(X[r])\n",
    "            labels.append(y[r])\n",
    "            y_hat.append(text_labels[np.argmax(batch_out[r].detach().numpy())])\n",
    "        break\n",
    "    fig, axes = plt.subplots(num_rows, num_cols)\n",
    "\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index < num_images:\n",
    "                ax = axes[i, j]\n",
    "                ax.imshow(images[index].view((28, 28)).numpy())\n",
    "                ax.set_title(\n",
    "                    text_labels[labels[index].item()] + '\\n' + y_hat[index]\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T11:32:57.410594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_ten_prediction(test_iter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_ten_prediction(test_iter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
